
---
layout:default
titile:A few useful things to know about machine learning notes by lostmarble
---
<h2> {{ page.title }} </h2>
<p> 这篇文章介绍了机器学习研究者目前学到的几个点，对于研究机器的入门者有很大的参考价值，它能给你一些key insight</p>
<p>1.learning = Representation + Evaluation + Optimization</p>
     通常来说Representation即特征，Evaluation即目标方程，即找到最优目标方程的过程
   2.It's Generalization that counts.
     模型的泛化能力(generalization)才是最重要的
   3.Data alone is not enough.
     仅仅使用数据本身是远远不够的
     对于多元变量的boolean方程，它的定义域是呈指数式增长的，也就是说我们收集的数据是远远不够的。但这点并不是很令人沮丧，因为我们对要学习的方法加入了一些
     限制，如平滑性、相似的数据应该被划分成一个类、受限的依赖性、受限的复杂度，这也是机器学习能够成功的原因。
   4.Overfitting has many faces
     one way to understand overfitting is by decomposing generalization error into bias and variance. Bias is a learner's tendency to consistently learn the
     same wrong thing. Variance is the tendency to learn random things irrespective of the real signal.
     cross-validation,regularization term,statistical significance test.
     overfitting is not caused by noise.
   5.Intuition fails in High Dimensions
     our intuitions, which come from three-dimensional world,often do not apply in hight-dimensional ones.
   6.Theoretical guarantees are not what they seem
     one of the major developments of recent decades has been the realization that we can have guarantees on the results of induction, particularly if we are
     willing to settle for probablistic guarantees.
   7.Feature engineering is the key
   8.More data beats a cleverer algorithm.
   9.Learning many models,Not just one.
   10.Simplicity does not imply accuracy.
   11.Representable does not imply learnable.
   12.Correlation does not imply causation.
